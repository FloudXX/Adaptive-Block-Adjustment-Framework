{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DemVCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, act_layer=nn.GELU, drop=0., pred=True):\n",
    "        super().__init__()\n",
    "        #out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.q = nn.Linear(in_features, in_features)\n",
    "        self.k = nn.Linear(in_features, in_features)\n",
    "        self.v = nn.Linear(in_features, in_features)\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.fc3 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.fc4 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.fc5 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.fc6 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.pred = pred\n",
    "        self.drop = nn.Dropout(drop)\n",
    "            \n",
    "        if pred==True:\n",
    "            self.fcx = nn.Linear(hidden_features,1)\n",
    "        else:\n",
    "            self.fcx = nn.Linear(hidden_features, in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        q = self.q(x).unsqueeze(2)\n",
    "        k = self.k(x).unsqueeze(2)\n",
    "        v = self.v(x).unsqueeze(2)\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        attn = attn/np.sqrt(k.size(-2))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).squeeze(2)\n",
    "        x += x0\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.act(x)\n",
    "    \n",
    "        x = self.drop(x)\n",
    "        x = self.fcx(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF(nn.Module):\n",
    "    def __init__(self, in_features, ftout_feature,act_layer=nn.GELU,drop=0.):\n",
    "        super().__init__()\n",
    "        self.ft1 = nn.Linear(in_features, ftout_feature)\n",
    "        self.ft2 = nn.Linear(ftout_feature, ftout_feature)\n",
    "        self.Block1 = Mlp(in_features=ftout_feature, hidden_features=64, act_layer=nn.GELU, drop=drop, pred=False)\n",
    "        self.Block2 = Mlp(in_features=ftout_feature, hidden_features=64, act_layer=nn.GELU, drop=drop, pred=True)\n",
    "        self.act = act_layer()\n",
    "    def forward(self, x):\n",
    "        x=self.ft1(x)\n",
    "        x = self.act(x)\n",
    "        x=self.ft2(x)\n",
    "        x = self.act(x)\n",
    "        return self.Block2(self.Block1(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Modify the number of input features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    #net = nn.Sequential(nn.Linear(in_features, 64), nn.ReLU(), nn.Linear(64,1)).to(device)\n",
    "    net = TF(in_features=8,ftout_feature=2, drop=0.).to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training sub-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "# Set Loss function\n",
    "def rmse(net, features, labels):\n",
    "    preds = net(features)\n",
    "    mse = loss(preds, labels)  \n",
    "    rmse = torch.sqrt(mse)  \n",
    "    return rmse.item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def train(\n",
    "    net,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "    train_ls, test_ls = [], []\n",
    "    best_score = 9999\n",
    "    best_epoch = 0\n",
    "    train_iter = load_array((train_features, train_labels), batch_size)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    for epoch in trange(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_ls.append(rmse(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_score = rmse(net, test_features, test_labels)\n",
    "            test_ls.append(test_score)\n",
    "            if best_score > test_score:\n",
    "                best_score = test_score\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(net.state_dict(), Net_Save_path_pre+\"/tempnet.pth\")\n",
    "\n",
    "    return train_ls, test_ls, best_score, best_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### шонч╗Г"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and pred\n",
    "def train_and_pred(\n",
    "    train_features,\n",
    "    test_features,\n",
    "    train_labels,\n",
    "    test_labels,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "    dataset_index,\n",
    "):\n",
    "    net = get_net()\n",
    "    print(next(net.parameters()).device)\n",
    "    \n",
    "    train_ls, test_ls, best_score, best_epoch = train(\n",
    "        net,\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        test_features,\n",
    "        test_labels,\n",
    "        num_epochs,\n",
    "        lr,\n",
    "        weight_decay,\n",
    "        batch_size,\n",
    "    )\n",
    "    train_ls_all = []\n",
    "    train_ls_all.append(train_ls)\n",
    "    test_ls_all = []\n",
    "    test_ls_all.append(test_ls)\n",
    "    print(next(net.parameters()).device)\n",
    "\n",
    "    # Paint\n",
    "    plt.plot(np.arange(1, num_epochs + 1, 1), train_ls_all[0], \"b\")\n",
    "    plt.plot(np.arange(1, num_epochs + 1, 1), test_ls_all[0], \"r\")\n",
    "    plt.xlabel(\"epoch\"), plt.ylabel(\"rmse\")\n",
    "    plt.legend([\"train\", \"test\"])\n",
    "    plt.grid(True)\n",
    "    plt.savefig(Net_Save_path_pre+\"/\"+ str(dataset_index)+\".png\")\n",
    "    plt.show()\n",
    "    print(f\"train log rmse {float(train_ls[-1]):f}\")\n",
    "\n",
    "    # Read and store the best model\n",
    "    net.load_state_dict(torch.load(Net_Save_path_pre+\"/tempnet.pth\"))\n",
    "    torch.save(net.state_dict(),Net_Save_path_pre+\"/\"+ str(dataset_index)+ \".pth\")\n",
    "    print(next(net.parameters()).device)\n",
    "    return net,best_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict and analyze errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predict_error(net, features, labels):\n",
    "    preds = net(features).cpu().detach().numpy()\n",
    "    truth= labels.cpu().detach().numpy()\n",
    "    h_error=truth-preds\n",
    "\n",
    "    model_mae = mean_absolute_error(truth, preds)\n",
    "    model_rmse = sqrt(mean_squared_error(truth, preds))\n",
    "    model_r2 = r2_score(truth, preds)\n",
    "\n",
    "    abs_error = []\n",
    "    error2 = []\n",
    "    for i in range(0, len(h_error)):\n",
    "        abs_error.append(abs(h_error[i]))\n",
    "        error2.append(pow(h_error[i], 2))\n",
    "    abs_error.sort()\n",
    "    mean = sum(h_error) / len(error2)\n",
    "    mae = sum(abs_error) / len(error2)\n",
    "    abs_mid = abs_error[int(len(abs_error) / 2)]\n",
    "    abs_max = abs_error[len(abs_error)-1]\n",
    "    le90 = abs_error[int(len(abs_error) * 0.9)]\n",
    "    rmse = pow((sum(error2) / len(error2)), 0.5)\n",
    "\n",
    "    return model_mae,model_rmse,model_r2,mean[0], mae[0], abs_mid[0], abs_max[0], le90[0], rmse[0],h_error\n",
    "    # return model_mae[0],model_rmse[0],model_r2[0],mean[0], mae[0], abs_mid[0], abs_max[0], le90[0], rmse[0],h_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Network hyperparameter Settings\n",
    "'''\n",
    "Note that the amount of data should not be an integer multiple of batch_size +1. \n",
    "For example, if bacth_size=64 and the number of training sets is 321, \n",
    "the shape of the last batch will be (1,feature_num), \n",
    "which may turn into a one-dimensional matrix during the output of the inner network, leading to errors\n",
    "'''\n",
    "num_epochs, lr, weight_decay, batch_size = 3, 0.0005, 0.01, 128\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Select training equipment\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Read all HCPs\n",
    "CP_all = pd.read_excel(\"dataset/CP/GDCPs_8f3c.xlsx\")\n",
    "\n",
    "# Set the path and quantity of the dataset\n",
    "data_path_pre = 'dataset/CP/Select_CP_BestPosition/RMSE9_Bagging/'\n",
    "data_num=7\n",
    "MAX_train_num=1000 \n",
    "MAX_train_frac=0.5   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "# Analysis of fitting results and errors after adjustment\n",
    "Final_Herr=np.zeros((data_num*2,11)) # 11 = The number of HCPS, the optimal number of rounds, model evaluation ME*3, error evaluation EE*6\n",
    "\n",
    "# Error table after adjustment\n",
    "col0 = \"Terrain classification\"\n",
    "col1 = \"Land cover\"\n",
    "col2 = \"Vegetation coverage\"\n",
    "col3 = \"dZ\"\n",
    "\n",
    "Data_Save_path_pre=\"dataset/EA/CP_error_afterEA/TETF/ep\"+str(num_epochs)+'_lr'+str(lr)+'_bs'+str(batch_size)\n",
    "Net_Save_path_pre=\"dataset/EA/TETF_netsave/ep\"+str(num_epochs)+'_lr'+str(lr)+'_bs'+str(batch_size)\n",
    "if not os.path.exists(Data_Save_path_pre):\n",
    "    os.makedirs(Data_Save_path_pre)\n",
    "if not os.path.exists(Net_Save_path_pre):\n",
    "    os.makedirs(Net_Save_path_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,data_num):\n",
    "for i in range(0, 1):\n",
    "    # for i in (0, 1, 2, 3):\n",
    "    # Read data\n",
    "    print(\"Dataset:\" + str(i) )\n",
    "    temp_CP_index = pd.read_excel(data_path_pre + str(i) + \"0.xlsx\")\n",
    "    temp_CP_data = pd.concat(\n",
    "        (CP_all.iloc[temp_CP_index.iloc[:, 0], 0:-1], temp_CP_index.set_index(\"CP_index\")), axis=1\n",
    "    )\n",
    "\n",
    "    # Divide the training/test data\n",
    "    if temp_CP_data.shape[0] / 2 > MAX_train_num:\n",
    "        train_raw = temp_CP_data.sample(MAX_train_num, random_state=0)\n",
    "        test_raw = temp_CP_data.drop(train_raw.index)\n",
    "    else:\n",
    "        train_raw = temp_CP_data.sample(frac=MAX_train_frac, random_state=0)\n",
    "        test_raw = temp_CP_data.drop(train_raw.index)\n",
    "    print(\n",
    "        \"Training set size\" + str(train_raw.shape[0]) + \",Test set size\" + str(test_raw.shape[0]),\n",
    "    )\n",
    "    print(\"Partial data display\")\n",
    "    print(train_raw.iloc[0:4])\n",
    "    print(\" \")\n",
    "\n",
    "    # Data preprocessing\n",
    "    # Merge the data used\n",
    "    combine_features_raw = pd.concat(\n",
    "        (\n",
    "            train_raw.iloc[:, 0:-4],\n",
    "            test_raw.iloc[:, 0:-4],\n",
    "        )\n",
    "    )\n",
    "    combine_features = combine_features_raw.copy()\n",
    "    combine_label_raw = pd.concat(\n",
    "        (\n",
    "            train_raw.iloc[:, -4:],\n",
    "            test_raw.iloc[:, -4:],\n",
    "        )\n",
    "    )\n",
    "    combine_label = combine_label_raw.copy()\n",
    "\n",
    "    # Standardization\n",
    "    combine_features.iloc[:, 0:-4] = combine_features.iloc[:, 0:-4].apply(\n",
    "        lambda x: (x - x.mean()) / (x.std())\n",
    "    )\n",
    "    combine_features.iloc[:, 0:-4] = combine_features.iloc[:, 0:-4].fillna(0)\n",
    "    print(\"Part of the processed data is displayed\")\n",
    "    print(combine_features.iloc[0:4])\n",
    "    print(\" \")\n",
    "\n",
    "    # Convert to Tensor data\n",
    "    n_train = train_raw.shape[0]\n",
    "    train_features = torch.tensor(combine_features[:n_train].values, dtype=torch.float32).to(device)\n",
    "    test_features = torch.tensor(combine_features[n_train:].values, dtype=torch.float32).to(device)\n",
    "    all_features = torch.tensor(combine_features.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_labels = torch.tensor(combine_label[:n_train].values, dtype=torch.float32).to(device)\n",
    "    test_labels = torch.tensor(combine_label[n_train:].values, dtype=torch.float32).to(device)\n",
    "    all_labels = torch.tensor(combine_label.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Training\n",
    "    Best_net, Best_epoch = train_and_pred(\n",
    "        train_features,\n",
    "        test_features,\n",
    "        train_labels[:, -1].reshape(-1, 1),\n",
    "        test_labels[:, -1].reshape(-1, 1),\n",
    "        num_epochs,\n",
    "        lr,\n",
    "        weight_decay,\n",
    "        batch_size,\n",
    "        i,\n",
    "    )\n",
    "\n",
    "    # Prediction/Save\n",
    "    # Test set\n",
    "    ME_1,ME_2,ME_3,EE_1,EE_2,EE_3,EE_4,EE_5,EE_6,Herror = calculate_predict_error(\n",
    "        Best_net, test_features, test_labels[:, -1].reshape(-1, 1),\n",
    "    )\n",
    "    Final_Herr[i, :] = [Herror.shape[0], Best_epoch, ME_1, ME_2, ME_3, EE_1, EE_2, EE_3, EE_4, EE_5, EE_6]\n",
    "\n",
    "    print(\"Best Turn:{}\".format(Best_epoch))\n",
    "    print(\"Model fitting  MAE:{:.2f},RMSE:{:.2f},R2:{:.2f}\".format(ME_1,ME_2, ME_3))\n",
    "    print(\"Elevation accuracy (Test):  MEAN:{:.2f},MAE:{:.2f},RMSE:{:.2f}\".format(EE_1,EE_2, EE_6))\n",
    "    # Complete dataset\n",
    "    ME_1,ME_2,ME_3,EE_1,EE_2,EE_3,EE_4,EE_5,EE_6,Herror = calculate_predict_error(\n",
    "        Best_net, all_features, all_labels[:, -1].reshape(-1, 1),\n",
    "    )\n",
    "    Final_Herr[i+data_num, 0:11] = [Herror.shape[0], 0, ME_1, ME_2, ME_3, EE_1, EE_2, EE_3, EE_4, EE_5, EE_6]\n",
    "    output_data = pd.DataFrame(\n",
    "        {\n",
    "            col0: all_labels[:, -4].cpu().detach().numpy(),\n",
    "            col1: all_labels[:, -3].cpu().detach().numpy(),\n",
    "            col2: all_labels[:, -2].cpu().detach().numpy(),\n",
    "            col3: Herror.flatten(),\n",
    "        }\n",
    "    )\n",
    "    output_data.to_excel(\n",
    "        Data_Save_path_pre+\"/\" + str(i) + \".xlsx\",\n",
    "        sheet_name=\"sheet1\",\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Elevation accuracy (Complete):   MEAN:{:.2f},MAE:{:.2f},RMSE:{:.2f}\".format(EE_1,EE_2, EE_6))\n",
    "\n",
    "    print(\" \")\n",
    "    print(\" \")\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the elevation error after adjustment\n",
    "# col0 = \"CP_num\"\n",
    "# col1 = \"Best_epoch\"\n",
    "# col2 = \"Model_MAE\"\n",
    "# col3 = \"Model_RMSE\"\n",
    "# col4 = \"Model_R2\"\n",
    "# col5 = \"MEAN\"\n",
    "# col6 = \"MAE\"\n",
    "# col7 = \"MID\"\n",
    "# col8 = \"MAX\"\n",
    "# col9 = \"LE90\"\n",
    "# col10 = \"RMSE\"\n",
    "\n",
    "# data = pd.DataFrame(\n",
    "#     {\n",
    "#         col0: Final_Herr[:, 0],\n",
    "#         col1: Final_Herr[:, 1],\n",
    "#         col2: Final_Herr[:, 2],\n",
    "#         col3: Final_Herr[:, 3],\n",
    "#         col4: Final_Herr[:, 4],\n",
    "#         col5: Final_Herr[:, 5],\n",
    "#         col6: Final_Herr[:, 6],\n",
    "#         col7: Final_Herr[:, 7],\n",
    "#         col8: Final_Herr[:, 8],\n",
    "#         col9: Final_Herr[:, 9],\n",
    "#         col10: Final_Herr[:, 10],\n",
    "#     }\n",
    "# )\n",
    "# data.to_excel('output/EA/Final_Herr_TETF/ep'+str(num_epochs)+'_lr'+str(lr)+'_bs'+str(batch_size)+'.xlsx', sheet_name=\"sheet1\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
